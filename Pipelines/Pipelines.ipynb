{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines using Pandas.\n",
    "\n",
    "# David Brookes July 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Application Date</th>\n",
       "      <th>Permit Status</th>\n",
       "      <th>Permit Type</th>\n",
       "      <th>Event Category</th>\n",
       "      <th>Event Sub-Category</th>\n",
       "      <th>Name of Event</th>\n",
       "      <th>Year-Month-App#</th>\n",
       "      <th>Event Start Date</th>\n",
       "      <th>Event End Date</th>\n",
       "      <th>Event Location - Park</th>\n",
       "      <th>Event Location - Neighborhood</th>\n",
       "      <th>Council District</th>\n",
       "      <th>Precinct</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>Charter Vessel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy - Lady Mary</td>\n",
       "      <td>CV14JY314</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy LP</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Charter Vessel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy - Celebrations</td>\n",
       "      <td>CV14JY315</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy LP</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Charter Vessel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy - Goodtime 3</td>\n",
       "      <td>CV14JY316</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy LP</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Charter Vessel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy - Sightseer</td>\n",
       "      <td>CV14JY317</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy LP</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Charter Vessel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy - Champagne Lady</td>\n",
       "      <td>CV14JY318</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>07/04/2014 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argosy LP</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Application Date Permit Status     Permit Type Event Category  \\\n",
       "0              NaN     Cancelled  Charter Vessel            NaN   \n",
       "1              NaN      Complete  Charter Vessel            NaN   \n",
       "2              NaN      Complete  Charter Vessel            NaN   \n",
       "3              NaN      Complete  Charter Vessel            NaN   \n",
       "4              NaN      Complete  Charter Vessel            NaN   \n",
       "\n",
       "  Event Sub-Category            Name of Event Year-Month-App#  \\\n",
       "0                NaN       Argosy - Lady Mary       CV14JY314   \n",
       "1                NaN    Argosy - Celebrations       CV14JY315   \n",
       "2                NaN      Argosy - Goodtime 3       CV14JY316   \n",
       "3                NaN       Argosy - Sightseer       CV14JY317   \n",
       "4                NaN  Argosy - Champagne Lady       CV14JY318   \n",
       "\n",
       "         Event Start Date          Event End Date Event Location - Park  \\\n",
       "0  07/04/2014 12:00:00 AM  07/04/2014 12:00:00 AM                   NaN   \n",
       "1  07/04/2014 12:00:00 AM  07/04/2014 12:00:00 AM                   NaN   \n",
       "2  07/04/2014 12:00:00 AM  07/04/2014 12:00:00 AM                   NaN   \n",
       "3  07/04/2014 12:00:00 AM  07/04/2014 12:00:00 AM                   NaN   \n",
       "4  07/04/2014 12:00:00 AM  07/04/2014 12:00:00 AM                   NaN   \n",
       "\n",
       "  Event Location - Neighborhood Council District Precinct Organization  \\\n",
       "0                       Fremont              NaN      NaN    Argosy LP   \n",
       "1                       Fremont              NaN      NaN    Argosy LP   \n",
       "2                       Fremont              NaN      NaN    Argosy LP   \n",
       "3                       Fremont              NaN      NaN    Argosy LP   \n",
       "4                       Fremont              NaN      NaN    Argosy LP   \n",
       "\n",
       "   Attendance  \n",
       "0       170.0  \n",
       "1       100.0  \n",
       "2       170.0  \n",
       "3       130.0  \n",
       "4        90.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'D:\\My Documents\\Python Code\\Pipelines\\Special_Events_Permits.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['application_date', 'permit_status', 'permit_type', 'event_category',\n",
      "       'event_sub-category', 'name_of_event', 'year-month-app#',\n",
      "       'event_start_date', 'event_end_date', 'event_location_-_park',\n",
      "       'event_location_-_neighborhood', 'council_district', 'precinct',\n",
      "       'organization', 'attendance'],\n",
      "      dtype='object')\n",
      "(3433, 15)\n"
     ]
    }
   ],
   "source": [
    "# Convert column names to lower case with underscores.\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "print(df.columns)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "07/04/2014 12:00:00 AM\n"
     ]
    }
   ],
   "source": [
    "print(type(df['event_start_date'][0]))\n",
    "print(df['event_start_date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "4\n",
      "2014\n",
      "12:00:00 AM\n"
     ]
    }
   ],
   "source": [
    "# Function to extract time information.\n",
    "\n",
    "time_info = df['event_start_date'][0]\n",
    "\n",
    "def extract_info(time_info):\n",
    "    month = int(time_info[0:2])\n",
    "    day = int(time_info[3:5])\n",
    "    year = int(time_info[6:10])\n",
    "    time = time_info[11:19]\n",
    "    am_pm = time_info[20:22]\n",
    "    \n",
    "    return (month, day, year, time, am_pm)\n",
    "    \n",
    "month, day, year, time, am_pm = extract_info(time_info)\n",
    "\n",
    "print(month)\n",
    "print(day)\n",
    "print(year)\n",
    "print(time, am_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          application_date permit_status     permit_type event_category  \\\n",
      "27  05/31/2016 12:00:00 AM      Complete  Charter Vessel            NaN   \n",
      "28  05/31/2016 12:00:00 AM      Complete  Charter Vessel            NaN   \n",
      "29  06/01/2016 12:00:00 AM      Complete  Charter Vessel            NaN   \n",
      "30  06/01/2016 12:00:00 AM      Complete  Charter Vessel            NaN   \n",
      "31  06/01/2016 12:00:00 AM      Complete  Charter Vessel            NaN   \n",
      "\n",
      "   event_sub-category                        name_of_event year-month-app#  \\\n",
      "27                NaN  Sternwheeler Charters - Christine W       CV16JY325   \n",
      "28                NaN         Anchor Bay Charters - Seeker       CV16JY326   \n",
      "29                NaN       Waterways Cruises-Emerald Star       CV16JY328   \n",
      "30                NaN       Waterways Cruises-Olympic Star       CV16JY329   \n",
      "31                NaN          Waterways Cruises-West Star       CV16JY330   \n",
      "\n",
      "          event_start_date          event_end_date event_location_-_park  \\\n",
      "27  07/04/2016 12:00:00 AM  07/04/2016 12:00:00 AM                   NaN   \n",
      "28  07/04/2016 12:00:00 AM  07/04/2016 12:00:00 AM                   NaN   \n",
      "29  07/04/2016 12:00:00 AM  07/04/2016 12:00:00 AM                   NaN   \n",
      "30  07/04/2016 12:00:00 AM  07/04/2016 12:00:00 AM                   NaN   \n",
      "31  07/04/2016 12:00:00 AM  07/04/2016 12:00:00 AM                   NaN   \n",
      "\n",
      "   event_location_-_neighborhood council_district precinct  \\\n",
      "27                   Wallingford                4    North   \n",
      "28                   Wallingford                4    North   \n",
      "29                   Wallingford                4    North   \n",
      "30                   Wallingford                4    North   \n",
      "31                   Wallingford                4    North   \n",
      "\n",
      "                organization  attendance  \n",
      "27  Stenwheeler Charters LLC        49.0  \n",
      "28       Anchor Bay Charters        30.0  \n",
      "29         Waterways Cruises       100.0  \n",
      "30         Waterways Cruises        90.0  \n",
      "31         Waterways Cruises        70.0  \n",
      "(529, 15)\n"
     ]
    }
   ],
   "source": [
    "# Just look at a selection of the data i.e. from 2016.\n",
    "booleans=[]\n",
    "for time_info in df['event_start_date']:\n",
    "    month, day, year, time, am_pm = extract_info(time_info)\n",
    "    if year == 2016:\n",
    "        booleans.append(True)\n",
    "    else:\n",
    "        booleans.append(False)\n",
    "        \n",
    "df_2016 = df[booleans]\n",
    "\n",
    "print(df_2016.head())\n",
    "print(df_2016.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a machine learning model.\n",
    "- Outcome - permit_status\n",
    "    Binary - will event be \"Complete\" or not\n",
    "\n",
    "- Features \n",
    "    - everything else!\n",
    "    - Raw, transformed, combinations etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with scikit-learn.\n",
    "- Set aside test data. No peeking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define outcome, and also one feature only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_train = np.where(df_train['permit_status'] == 'Complete', 1, 0)\n",
    "y_test = np.where(df_test['permit_status'] == 'Complete', 1, 0)\n",
    "\n",
    "# One feature used.\n",
    "X_train = df_train[['attendance']].fillna(value=0)\n",
    "X_test = df_test[['attendance']].fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "# Create model object.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit model and predict on training data.\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "p_pred_train = model.predict_proba(X_train)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_base: 0.5\n",
      "auc_test: 0.3961004273504274\n"
     ]
    }
   ],
   "source": [
    "# Evaluation.\n",
    "\n",
    "# Predict on test data.\n",
    "p_baseline = [y_train.mean()]*len(y_test) # Simple model that predicts the mean.\n",
    "p_pred_test = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Measure performance on the test set.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc_base = roc_auc_score(y_test, p_baseline)\n",
    "auc_test = roc_auc_score(y_test, p_pred_test)\n",
    "\n",
    "print('auc_base:', auc_base)\n",
    "print('auc_test:', auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several transformations of the data may be required.\n",
    "# For example, imputation followed by creating of polynomial features\n",
    "# followed by standardisation.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (PolynomialFeatures,\n",
    "                                  StandardScaler)\n",
    "#imputer = SimpleImputer()\n",
    "#quadratic = PolynomialFeatures()\n",
    "#standardiser = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of writing this:-   \\\n",
    "X_train_imp = imputer.fit_transform(X_train_raw)   \\\n",
    "X_train_quad = quadratic.fit_transform(X_train_imp)   \\\n",
    "X_train = standardiser.fit_transform(X_train_quad)   \n",
    "\n",
    "and\n",
    "\n",
    "X_test_imp = imputer.transform(X_test_raw)   \\\n",
    "X_test_quad = quadratic.transform(X_test_imp)   \\\n",
    "X_test = standardiser.transform(X_test_quad)   \n",
    "\n",
    "Create a pipeline instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('imputer', SimpleImputer())\n",
    "                        ,('quadratic', PolynomialFeatures())\n",
    "                        ,('standardiser', StandardScaler())])\n",
    "\n",
    "X_train_pipeline_processed = pipeline.fit_transform(X_train)\n",
    "X_test_pipeline_processed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      attendance\n",
      "1184       325.0\n",
      "1320       705.0\n",
      "1564       310.0\n",
      "1282      2000.0\n",
      "1233      3600.0\n",
      "...          ...\n",
      "1251        60.0\n",
      "1511       250.0\n",
      "37          30.0\n",
      "1362       705.0\n",
      "1298      5030.0\n",
      "\n",
      "[396 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.21186911 -0.10205332]\n",
      " [ 0.         -0.19234759 -0.10195311]\n",
      " [ 0.         -0.2126397  -0.10205576]\n",
      " ...\n",
      " [ 0.         -0.22702398 -0.10208013]\n",
      " [ 0.         -0.19234759 -0.10195311]\n",
      " [ 0.          0.02983817 -0.09560263]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pipeline_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      attendance\n",
      "1184    5.786897\n",
      "1320    6.559615\n",
      "1564    5.739793\n",
      "1282    7.601402\n",
      "1233    8.188967\n",
      "...          ...\n",
      "1251    4.110874\n",
      "1511    5.525453\n",
      "37      3.433987\n",
      "1362    6.559615\n",
      "1298    8.523374\n",
      "\n",
      "[396 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# A useful function - FunctionTransformer().\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "logger = FunctionTransformer(np.log1p) # Choose any function you like.\n",
    "\n",
    "X_train_log = logger.transform(X_train)\n",
    "print(X_train_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, create a custom transformer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      attendance\n",
      "1184    5.786897\n",
      "1320    6.559615\n",
      "1564    5.739793\n",
      "1282    7.601402\n",
      "1233    8.188967\n",
      "...          ...\n",
      "1251    4.110874\n",
      "1511    5.525453\n",
      "37      3.433987\n",
      "1362    6.559615\n",
      "1298    8.523374\n",
      "\n",
      "[396 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class Log1pTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        Xlog = np.log1p(X)\n",
    "        return Xlog\n",
    "    \n",
    "logger_custom = Log1pTransformer()\n",
    "X_train_logger_custom = logger_custom.fit_transform(X_train) # Note TransformerMixin creates fit_transform method.\n",
    "\n",
    "print(X_train_logger_custom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
